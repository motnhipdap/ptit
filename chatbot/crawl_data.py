"""
Script crawl d·ªØ li·ªáu tuy·ªÉn sinh t·ª´ website
S·ª≠ d·ª•ng: requests + BeautifulSoup
"""

# pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup
import os
import time


def crawl_page(url, output_file):
    """Crawl n·ªôi dung text t·ª´ m·ªôt trang web v√† l∆∞u v√†o file .txt"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = "utf-8"
        soup = BeautifulSoup(response.text, "html.parser")

        # Lo·∫°i b·ªè script, style, nav, footer
        for tag in soup(["script", "style", "nav", "footer", "header"]):
            tag.decompose()

        # L·∫•y n·ªôi dung text
        text = soup.get_text(separator="\n", strip=True)

        # Lo·∫°i b·ªè d√≤ng tr·ªëng th·ª´a
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        clean_text = "\n".join(lines)

        # L∆∞u v√†o file
        os.makedirs("data", exist_ok=True)
        with open(f"data/{output_file}", "w", encoding="utf-8") as f:
            f.write(clean_text)

        print(f"‚úÖ ƒê√£ l∆∞u: data/{output_file} ({len(clean_text)} k√Ω t·ª±)")
        return clean_text

    except Exception as e:
        print(f"‚ùå L·ªói khi crawl {url}: {e}")
        return None


# ==============================
# DANH S√ÅCH URL C·∫¶N CRAWL
# ==============================
# Thay ƒë·ªïi URL theo tr∆∞·ªùng b·∫°n mu·ªën l·∫•y d·ªØ li·ªáu

urls = [
    # === PTIT - H·ªçc vi·ªán C√¥ng ngh·ªá B∆∞u ch√≠nh Vi·ªÖn th√¥ng ===
    ("https://tuyensinh.ptit.edu.vn", "ptit_trangchu.txt"),
    ("https://tuyensinh.ptit.edu.vn/thong-bao-diem-chuan-trung-tuyen-vao-dai-hoc-he-chinh-quy-nam-2025/", "ptit_diemchuan_2025.txt"),
    ("https://tuyensinh.ptit.edu.vn/gioi-thieu/xem-diem-cac-nam-truoc/diem-trung-tuyen-2024/", "ptit_diemchuan_2024.txt"),
    ("https://tuyensinh.ptit.edu.vn/gioi-thieu/cau-hoi-thuong-gap/", "ptit_faq.txt"),
    ("https://tuyensinh.ptit.edu.vn/gioi-thieu/chinh-sach-hoc-bong/", "ptit_hocbong.txt"),
    ("https://tuyensinh.ptit.edu.vn/thong-bao-thong-tin-chi-tiet-cac-phuong-thuc-tuyen-sinh-dai-hoc-he-chinh-quy-nam-2026/", "ptit_phuongthuc_2026.txt"),

    # === B√ÅCH KHOA H√Ä N·ªòI ===
    ("https://ts.hust.edu.vn", "bachkhoa_trangchu.txt"),
    ("https://ts.hust.edu.vn/tin-tuc/du-kien-phuong-an-tuyen-sinh-dai-hoc-2026-cua-bach-khoa-ha-noi", "bachkhoa_phuongan_2026.txt"),
    ("https://ts.hust.edu.vn/tin-tuc/diem-chuan-dai-hoc-bach-khoa-ha-noi-2024-diem-thi-dgtd-cao-nhat-83-82-diem-thi-tot-nghiep-thpt-cao-nhat-28-53", "bachkhoa_diemchuan_2024.txt"),
    ("https://ts.hust.edu.vn/training-cate/nganh-dao-tao-dai-hoc", "bachkhoa_nganhdaotao.txt"),
    ("https://ts.hust.edu.vn/tin-tuc/hoc-phi-dai-hoc-nam-2024-nien-khoa-2024-2025", "bachkhoa_hocphi.txt"),
]

if __name__ == "__main__":
    if not urls:
        print("‚ö†Ô∏è  Ch∆∞a c√≥ URL n√†o ƒë∆∞·ª£c c·∫•u h√¨nh.")
        print("H√£y th√™m URL v√†o danh s√°ch 'urls' trong file n√†y.")
        print("\nV√≠ d·ª•:")
        print('  ("https://tuyensinh.example.edu.vn/thong-tin", "thongtin.txt")')
        print("\nHo·∫∑c b·∫°n c√≥ th·ªÉ t·ª± t·∫°o file .txt trong th∆∞ m·ª•c data/ v·ªõi n·ªôi dung")
        print("tuy·ªÉn sinh copy t·ª´ website tr∆∞·ªùng.")
    else:
        for url, filename in urls:
            crawl_page(url, filename)
            time.sleep(2)  # Delay 2s gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã ch·∫∑n

        print(f"\nüéâ ƒê√£ crawl xong {len(urls)} trang!")
        print("Ti·∫øp theo, ch·∫°y: python prepare_data.py")
